{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7316554,"sourceType":"datasetVersion","datasetId":4245792}],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Optimizing Neural Networks with Keras Tuner on the Pima Diabetes Dataset","metadata":{}},{"cell_type":"markdown","source":"Neural network models are powerful tools for solving complex tasks, but finding the right architecture and hyperparameters can be a challenging and time-consuming process. Keras Tuner provides a solution to this problem by automating the hyperparameter tuning process, allowing you to efficiently search through a hyperparameter space and identify the optimal configuration for your neural network.\n\nIn this Kaggle notebook, we'll explore the application of Keras Tuner on the Pima Diabetes dataset. The dataset contains various health metrics for a group of patients, along with an indication of whether each patient developed diabetes or not. Our goal is to build and optimize a neural network to predict the onset of diabetes based on these features.","metadata":{}},{"cell_type":"markdown","source":"**Introduction to Keras Tuner:** Understand the basics of Keras Tuner, its key components, and how it can enhance the efficiency of your neural network development.\n\n","metadata":{}},{"cell_type":"markdown","source":"Load Dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\ndf = pd.read_csv('/kaggle/input/pima-diabetes/diabetes.csv')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.563260Z","iopub.execute_input":"2024-01-01T09:17:26.563627Z","iopub.status.idle":"2024-01-01T09:17:26.590783Z","shell.execute_reply.started":"2024-01-01T09:17:26.563597Z","shell.execute_reply":"2024-01-01T09:17:26.589616Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"**Exploratory Data Analysis (EDA):** Explore the Pima Diabetes dataset to gain insights into the distribution of features, identify potential challenges, and prepare the data for model training.","metadata":{}},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.592632Z","iopub.execute_input":"2024-01-01T09:17:26.592954Z","iopub.status.idle":"2024-01-01T09:17:26.609386Z","shell.execute_reply.started":"2024-01-01T09:17:26.592925Z","shell.execute_reply":"2024-01-01T09:17:26.607930Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.corr()['Outcome']","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.611289Z","iopub.execute_input":"2024-01-01T09:17:26.611992Z","iopub.status.idle":"2024-01-01T09:17:26.624064Z","shell.execute_reply.started":"2024-01-01T09:17:26.611942Z","shell.execute_reply":"2024-01-01T09:17:26.622573Z"},"trusted":true},"execution_count":32,"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"Pregnancies                 0.221898\nGlucose                     0.466581\nBloodPressure               0.065068\nSkinThickness               0.074752\nInsulin                     0.130548\nBMI                         0.292695\nDiabetesPedigreeFunction    0.173844\nAge                         0.238356\nOutcome                     1.000000\nName: Outcome, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"x = df.drop(['Outcome'],axis =1)\ny = df['Outcome']","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.626874Z","iopub.execute_input":"2024-01-01T09:17:26.627513Z","iopub.status.idle":"2024-01-01T09:17:26.635904Z","shell.execute_reply.started":"2024-01-01T09:17:26.627482Z","shell.execute_reply":"2024-01-01T09:17:26.634273Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx = scaler.fit_transform(x)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.638199Z","iopub.execute_input":"2024-01-01T09:17:26.638570Z","iopub.status.idle":"2024-01-01T09:17:26.651087Z","shell.execute_reply.started":"2024-01-01T09:17:26.638539Z","shell.execute_reply":"2024-01-01T09:17:26.650078Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nxtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size=.2,random_state=1)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.652221Z","iopub.execute_input":"2024-01-01T09:17:26.652922Z","iopub.status.idle":"2024-01-01T09:17:26.663966Z","shell.execute_reply.started":"2024-01-01T09:17:26.652893Z","shell.execute_reply":"2024-01-01T09:17:26.662763Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"markdown","source":"# Model Building with Keras:","metadata":{}},{"cell_type":"markdown","source":"Construct a baseline neural network using Keras, establishing a starting point for hyperparameter tuning.\n\n","metadata":{}},{"cell_type":"code","source":"import tensorflow \nfrom tensorflow import keras\nfrom keras import Sequential\nfrom keras.layers import Dense","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.665580Z","iopub.execute_input":"2024-01-01T09:17:26.666216Z","iopub.status.idle":"2024-01-01T09:17:26.674510Z","shell.execute_reply.started":"2024-01-01T09:17:26.666179Z","shell.execute_reply":"2024-01-01T09:17:26.673367Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(32, activation='relu', input_dim=8))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:26.675656Z","iopub.execute_input":"2024-01-01T09:17:26.676566Z","iopub.status.idle":"2024-01-01T09:17:26.716251Z","shell.execute_reply.started":"2024-01-01T09:17:26.676536Z","shell.execute_reply":"2024-01-01T09:17:26.715195Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"model.fit(xtrain,ytrain, batch_size=32, epochs=10,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:19:52.196041Z","iopub.execute_input":"2024-01-01T09:19:52.196710Z","iopub.status.idle":"2024-01-01T09:19:53.153689Z","shell.execute_reply.started":"2024-01-01T09:19:52.196665Z","shell.execute_reply":"2024-01-01T09:19:53.152410Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Epoch 1/10\n16/16 [==============================] - 0s 15ms/step - loss: 0.4930 - accuracy: 0.7739 - val_loss: 0.4606 - val_accuracy: 0.7805\nEpoch 2/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4876 - accuracy: 0.7739 - val_loss: 0.4582 - val_accuracy: 0.7805\nEpoch 3/10\n16/16 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.7719 - val_loss: 0.4555 - val_accuracy: 0.7642\nEpoch 4/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4795 - accuracy: 0.7760 - val_loss: 0.4534 - val_accuracy: 0.7480\nEpoch 5/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7760 - val_loss: 0.4529 - val_accuracy: 0.7398\nEpoch 6/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7739 - val_loss: 0.4513 - val_accuracy: 0.7398\nEpoch 7/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7760 - val_loss: 0.4501 - val_accuracy: 0.7398\nEpoch 8/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4681 - accuracy: 0.7739 - val_loss: 0.4502 - val_accuracy: 0.7398\nEpoch 9/10\n16/16 [==============================] - 0s 4ms/step - loss: 0.4659 - accuracy: 0.7719 - val_loss: 0.4493 - val_accuracy: 0.7317\nEpoch 10/10\n16/16 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.7739 - val_loss: 0.4479 - val_accuracy: 0.7317\n","output_type":"stream"},{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c29bbbf31f0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Advantage Of Keras Tune\n* Optimal Activation Function\n Keras Tune identifies and selects the activation function that yields the best accuracy for a given model.\n* Optimal Optimizer Selection:\n Keras Tune determines the most effective optimizer for training, optimizing the model's performance based on accuracy.\n* Dynamic Layer Addition:\n Keras Tune dynamically adds layers to the model based on the configuration that achieves the highest accuracy.\n\n","metadata":{}},{"cell_type":"markdown","source":"# Kares Tune For Select Appropriate Optimaizer","metadata":{}},{"cell_type":"code","source":"pip install -U keras-tuner","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:17:27.711521Z","iopub.execute_input":"2024-01-01T09:17:27.711818Z","iopub.status.idle":"2024-01-01T09:17:37.524957Z","shell.execute_reply.started":"2024-01-01T09:17:27.711794Z","shell.execute_reply":"2024-01-01T09:17:37.522946Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-tuner in /opt/conda/lib/python3.10/site-packages (1.4.6)\nRequirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.13.1)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (2.31.0)\nRequirement already satisfied: kt-legacy in /opt/conda/lib/python3.10/site-packages (from keras-tuner) (1.0.5)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras-tuner) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->keras-tuner) (2023.11.17)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"import kerastuner as kt\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\n\ndef build_model(hp):\n    model = Sequential()\n    model.add(Dense(32, activation='relu', input_dim=8))\n    model.add(Dense(1, activation='sigmoid'))\n\n    optimizer = hp.Choice('optimizer', values=['adam', 'sgd', 'rmsprop', 'adadelta'])\n    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:26:13.542267Z","iopub.execute_input":"2024-01-01T09:26:13.542643Z","iopub.status.idle":"2024-01-01T09:26:13.551782Z","shell.execute_reply.started":"2024-01-01T09:26:13.542613Z","shell.execute_reply":"2024-01-01T09:26:13.550095Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"# making tuner object\ntuner = kt.RandomSearch(build_model,\n                        objective='val_accuracy',\n                        max_trials=5)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:26:15.807280Z","iopub.execute_input":"2024-01-01T09:26:15.807840Z","iopub.status.idle":"2024-01-01T09:26:15.818240Z","shell.execute_reply.started":"2024-01-01T09:26:15.807808Z","shell.execute_reply":"2024-01-01T09:26:15.816970Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"Reloading Tuner from ./untitled_project/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner.search(xtrain,ytrain,epochs=5,validation_split=.02)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:26:28.911296Z","iopub.execute_input":"2024-01-01T09:26:28.911671Z","iopub.status.idle":"2024-01-01T09:26:28.917840Z","shell.execute_reply.started":"2024-01-01T09:26:28.911645Z","shell.execute_reply":"2024-01-01T09:26:28.916593Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"tuner.results_summary()\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:26:30.517498Z","iopub.execute_input":"2024-01-01T09:26:30.517883Z","iopub.status.idle":"2024-01-01T09:26:30.522858Z","shell.execute_reply.started":"2024-01-01T09:26:30.517853Z","shell.execute_reply":"2024-01-01T09:26:30.522224Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stdout","text":"Results summary\nResults in ./untitled_project\nShowing 10 best trials\nObjective(name=\"val_accuracy\", direction=\"max\")\n\nTrial 1 summary\nHyperparameters:\noptimizer: rmsprop\nScore: 0.7557003498077393\n\nTrial 2 summary\nHyperparameters:\noptimizer: adam\nScore: 0.7361563444137573\n\nTrial 3 summary\nHyperparameters:\noptimizer: sgd\nScore: 0.7149837017059326\n\nTrial 0 summary\nHyperparameters:\noptimizer: adadelta\nScore: 0.4576547145843506\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Getting Best Optimizer","metadata":{}},{"cell_type":"code","source":"tuner.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:31:54.883216Z","iopub.execute_input":"2024-01-01T09:31:54.883622Z","iopub.status.idle":"2024-01-01T09:31:54.892352Z","shell.execute_reply.started":"2024-01-01T09:31:54.883591Z","shell.execute_reply":"2024-01-01T09:31:54.891110Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"{'optimizer': 'rmsprop'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Now you can choose the model with rms optimizer by this code","metadata":{}},{"cell_type":"code","source":"model = tuner.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:35:28.519294Z","iopub.execute_input":"2024-01-01T09:35:28.519670Z","iopub.status.idle":"2024-01-01T09:35:29.098682Z","shell.execute_reply.started":"2024-01-01T09:35:28.519639Z","shell.execute_reply":"2024-01-01T09:35:29.096928Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:35:37.686898Z","iopub.execute_input":"2024-01-01T09:35:37.687276Z","iopub.status.idle":"2024-01-01T09:35:37.707758Z","shell.execute_reply.started":"2024-01-01T09:35:37.687246Z","shell.execute_reply":"2024-01-01T09:35:37.706560Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n dense (Dense)               (None, 32)                288       \n                                                                 \n dense_1 (Dense)             (None, 1)                 33        \n                                                                 \n=================================================================\nTotal params: 321 (1.25 KB)\nTrainable params: 321 (1.25 KB)\nNon-trainable params: 0 (0.00 Byte)\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Trian the model\nmodel.fit(xtrain,ytrain, batch_size=32, epochs=100,initial_epoch=6,validation_split=0.2) # initail  epochs is noting but skip epochs 1-5 which the tunner model already run","metadata":{"execution":{"iopub.status.busy":"2024-01-01T09:37:50.399123Z","iopub.execute_input":"2024-01-01T09:37:50.399486Z","iopub.status.idle":"2024-01-01T09:37:57.039831Z","shell.execute_reply.started":"2024-01-01T09:37:50.399454Z","shell.execute_reply":"2024-01-01T09:37:57.038915Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Epoch 7/100\n16/16 [==============================] - 1s 13ms/step - loss: 0.5152 - accuracy: 0.7536 - val_loss: 0.4695 - val_accuracy: 0.7967\nEpoch 8/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7699 - val_loss: 0.4642 - val_accuracy: 0.7967\nEpoch 9/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4993 - accuracy: 0.7678 - val_loss: 0.4601 - val_accuracy: 0.7805\nEpoch 10/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4940 - accuracy: 0.7699 - val_loss: 0.4575 - val_accuracy: 0.7805\nEpoch 11/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.7699 - val_loss: 0.4542 - val_accuracy: 0.7886\nEpoch 12/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.7719 - val_loss: 0.4523 - val_accuracy: 0.7886\nEpoch 13/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4817 - accuracy: 0.7780 - val_loss: 0.4502 - val_accuracy: 0.7967\nEpoch 14/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4785 - accuracy: 0.7862 - val_loss: 0.4478 - val_accuracy: 0.7967\nEpoch 15/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.7800 - val_loss: 0.4463 - val_accuracy: 0.7967\nEpoch 16/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4733 - accuracy: 0.7821 - val_loss: 0.4457 - val_accuracy: 0.7967\nEpoch 17/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7800 - val_loss: 0.4449 - val_accuracy: 0.7967\nEpoch 18/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4690 - accuracy: 0.7780 - val_loss: 0.4432 - val_accuracy: 0.7967\nEpoch 19/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4675 - accuracy: 0.7821 - val_loss: 0.4418 - val_accuracy: 0.7967\nEpoch 20/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.7780 - val_loss: 0.4410 - val_accuracy: 0.8049\nEpoch 21/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4639 - accuracy: 0.7800 - val_loss: 0.4396 - val_accuracy: 0.8049\nEpoch 22/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4625 - accuracy: 0.7821 - val_loss: 0.4394 - val_accuracy: 0.8049\nEpoch 23/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7800 - val_loss: 0.4393 - val_accuracy: 0.8049\nEpoch 24/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.7841 - val_loss: 0.4384 - val_accuracy: 0.8049\nEpoch 25/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7821 - val_loss: 0.4385 - val_accuracy: 0.8049\nEpoch 26/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4575 - accuracy: 0.7821 - val_loss: 0.4384 - val_accuracy: 0.7967\nEpoch 27/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4564 - accuracy: 0.7821 - val_loss: 0.4394 - val_accuracy: 0.8049\nEpoch 28/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4555 - accuracy: 0.7821 - val_loss: 0.4390 - val_accuracy: 0.8049\nEpoch 29/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7821 - val_loss: 0.4393 - val_accuracy: 0.7886\nEpoch 30/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4538 - accuracy: 0.7841 - val_loss: 0.4392 - val_accuracy: 0.7886\nEpoch 31/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.7862 - val_loss: 0.4391 - val_accuracy: 0.7967\nEpoch 32/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7862 - val_loss: 0.4397 - val_accuracy: 0.7886\nEpoch 33/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.7821 - val_loss: 0.4395 - val_accuracy: 0.7886\nEpoch 34/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4505 - accuracy: 0.7841 - val_loss: 0.4395 - val_accuracy: 0.7886\nEpoch 35/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7841 - val_loss: 0.4395 - val_accuracy: 0.7886\nEpoch 36/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.7841 - val_loss: 0.4397 - val_accuracy: 0.7886\nEpoch 37/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.7780 - val_loss: 0.4394 - val_accuracy: 0.7886\nEpoch 38/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4474 - accuracy: 0.7862 - val_loss: 0.4396 - val_accuracy: 0.7886\nEpoch 39/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.7800 - val_loss: 0.4398 - val_accuracy: 0.7886\nEpoch 40/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4460 - accuracy: 0.7800 - val_loss: 0.4401 - val_accuracy: 0.7886\nEpoch 41/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.7841 - val_loss: 0.4406 - val_accuracy: 0.7886\nEpoch 42/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.7780 - val_loss: 0.4410 - val_accuracy: 0.7886\nEpoch 43/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.7800 - val_loss: 0.4405 - val_accuracy: 0.7886\nEpoch 44/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.7780 - val_loss: 0.4405 - val_accuracy: 0.7886\nEpoch 45/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.7821 - val_loss: 0.4406 - val_accuracy: 0.7886\nEpoch 46/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.7780 - val_loss: 0.4402 - val_accuracy: 0.7886\nEpoch 47/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.7739 - val_loss: 0.4414 - val_accuracy: 0.7886\nEpoch 48/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.7821 - val_loss: 0.4414 - val_accuracy: 0.7886\nEpoch 49/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4400 - accuracy: 0.7841 - val_loss: 0.4415 - val_accuracy: 0.7886\nEpoch 50/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4397 - accuracy: 0.7780 - val_loss: 0.4422 - val_accuracy: 0.7886\nEpoch 51/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7821 - val_loss: 0.4419 - val_accuracy: 0.7886\nEpoch 52/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4384 - accuracy: 0.7821 - val_loss: 0.4428 - val_accuracy: 0.7886\nEpoch 53/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4384 - accuracy: 0.7780 - val_loss: 0.4430 - val_accuracy: 0.7805\nEpoch 54/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.7841 - val_loss: 0.4434 - val_accuracy: 0.7805\nEpoch 55/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4370 - accuracy: 0.7862 - val_loss: 0.4437 - val_accuracy: 0.7805\nEpoch 56/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4365 - accuracy: 0.7800 - val_loss: 0.4430 - val_accuracy: 0.7805\nEpoch 57/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.7821 - val_loss: 0.4433 - val_accuracy: 0.7805\nEpoch 58/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.7841 - val_loss: 0.4429 - val_accuracy: 0.7724\nEpoch 59/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4353 - accuracy: 0.7841 - val_loss: 0.4435 - val_accuracy: 0.7724\nEpoch 60/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4348 - accuracy: 0.7821 - val_loss: 0.4442 - val_accuracy: 0.7724\nEpoch 61/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4342 - accuracy: 0.7862 - val_loss: 0.4442 - val_accuracy: 0.7724\nEpoch 62/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4338 - accuracy: 0.7800 - val_loss: 0.4453 - val_accuracy: 0.7724\nEpoch 63/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4332 - accuracy: 0.7841 - val_loss: 0.4465 - val_accuracy: 0.7642\nEpoch 64/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.7821 - val_loss: 0.4464 - val_accuracy: 0.7642\nEpoch 65/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4323 - accuracy: 0.7800 - val_loss: 0.4454 - val_accuracy: 0.7724\nEpoch 66/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.7841 - val_loss: 0.4458 - val_accuracy: 0.7724\nEpoch 67/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7862 - val_loss: 0.4452 - val_accuracy: 0.7642\nEpoch 68/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.7800 - val_loss: 0.4456 - val_accuracy: 0.7724\nEpoch 69/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.7902 - val_loss: 0.4466 - val_accuracy: 0.7724\nEpoch 70/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.7902 - val_loss: 0.4462 - val_accuracy: 0.7642\nEpoch 71/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.7902 - val_loss: 0.4466 - val_accuracy: 0.7642\nEpoch 72/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7943 - val_loss: 0.4463 - val_accuracy: 0.7724\nEpoch 73/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.7963 - val_loss: 0.4461 - val_accuracy: 0.7724\nEpoch 74/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.7984 - val_loss: 0.4451 - val_accuracy: 0.7642\nEpoch 75/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.7943 - val_loss: 0.4460 - val_accuracy: 0.7642\nEpoch 76/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4272 - accuracy: 0.7963 - val_loss: 0.4456 - val_accuracy: 0.7724\nEpoch 77/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4269 - accuracy: 0.7963 - val_loss: 0.4456 - val_accuracy: 0.7642\nEpoch 78/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.7943 - val_loss: 0.4462 - val_accuracy: 0.7724\nEpoch 79/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.7984 - val_loss: 0.4462 - val_accuracy: 0.7642\nEpoch 80/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4259 - accuracy: 0.7963 - val_loss: 0.4466 - val_accuracy: 0.7724\nEpoch 81/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.7984 - val_loss: 0.4455 - val_accuracy: 0.7805\nEpoch 82/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.7984 - val_loss: 0.4460 - val_accuracy: 0.7886\nEpoch 83/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.7984 - val_loss: 0.4461 - val_accuracy: 0.7886\nEpoch 84/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8004 - val_loss: 0.4471 - val_accuracy: 0.7724\nEpoch 85/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8004 - val_loss: 0.4468 - val_accuracy: 0.7886\nEpoch 86/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4235 - accuracy: 0.8024 - val_loss: 0.4462 - val_accuracy: 0.7805\nEpoch 87/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4231 - accuracy: 0.8004 - val_loss: 0.4460 - val_accuracy: 0.7805\nEpoch 88/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8024 - val_loss: 0.4454 - val_accuracy: 0.7805\nEpoch 89/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4224 - accuracy: 0.8024 - val_loss: 0.4461 - val_accuracy: 0.7724\nEpoch 90/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.7963 - val_loss: 0.4467 - val_accuracy: 0.7724\nEpoch 91/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.8024 - val_loss: 0.4472 - val_accuracy: 0.7642\nEpoch 92/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4214 - accuracy: 0.7963 - val_loss: 0.4472 - val_accuracy: 0.7724\nEpoch 93/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4209 - accuracy: 0.8004 - val_loss: 0.4479 - val_accuracy: 0.7886\nEpoch 94/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4206 - accuracy: 0.8045 - val_loss: 0.4478 - val_accuracy: 0.7724\nEpoch 95/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8024 - val_loss: 0.4470 - val_accuracy: 0.7805\nEpoch 96/100\n16/16 [==============================] - 0s 3ms/step - loss: 0.4200 - accuracy: 0.8086 - val_loss: 0.4470 - val_accuracy: 0.7805\nEpoch 97/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4198 - accuracy: 0.7984 - val_loss: 0.4473 - val_accuracy: 0.7724\nEpoch 98/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4195 - accuracy: 0.8045 - val_loss: 0.4471 - val_accuracy: 0.7724\nEpoch 99/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4191 - accuracy: 0.8086 - val_loss: 0.4468 - val_accuracy: 0.7642\nEpoch 100/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.4189 - accuracy: 0.8024 - val_loss: 0.4482 - val_accuracy: 0.7642\n","output_type":"stream"},{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c2a04b599c0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Building Tune Model For Get Best Neuron Numbers","metadata":{}},{"cell_type":"code","source":"def build_model1(hp):\n    model = Sequential()\n    units = hp.Int('units', min_value=8, max_value=128, step=8)\n    model.add(Dense(units=units, activation='relu', input_dim=8))\n    model.add(Dense(1, activation='sigmoid'))\n    \n    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n    return model\n\n# create tuner object\ntuner1 = kt.RandomSearch(build_model1,\n                        objective='val_accuracy',\n                        max_trials=5,\n                        directory='mydir',\n                        project_name='tuner')\n\ntuner1.search(xtrain, ytrain, epochs=5, validation_split=0.2)\n","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:01:47.764179Z","iopub.execute_input":"2024-01-01T10:01:47.764566Z","iopub.status.idle":"2024-01-01T10:01:55.939076Z","shell.execute_reply.started":"2024-01-01T10:01:47.764536Z","shell.execute_reply":"2024-01-01T10:01:55.937963Z"},"trusted":true},"execution_count":106,"outputs":[{"name":"stdout","text":"Trial 5 Complete [00h 00m 02s]\nval_accuracy: 0.6016260385513306\n\nBest val_accuracy So Far: 0.7886179089546204\nTotal elapsed time: 00h 00m 08s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner1.results_summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:02:21.387198Z","iopub.execute_input":"2024-01-01T10:02:21.387558Z","iopub.status.idle":"2024-01-01T10:02:21.393228Z","shell.execute_reply.started":"2024-01-01T10:02:21.387528Z","shell.execute_reply":"2024-01-01T10:02:21.392321Z"},"trusted":true},"execution_count":107,"outputs":[{"name":"stdout","text":"Results summary\nResults in mydir/tuner\nShowing 10 best trials\nObjective(name=\"val_accuracy\", direction=\"max\")\n\nTrial 3 summary\nHyperparameters:\nunits: 80\nScore: 0.7886179089546204\n\nTrial 2 summary\nHyperparameters:\nunits: 112\nScore: 0.772357702255249\n\nTrial 0 summary\nHyperparameters:\nunits: 120\nScore: 0.7560975551605225\n\nTrial 1 summary\nHyperparameters:\nunits: 56\nScore: 0.7479674816131592\n\nTrial 4 summary\nHyperparameters:\nunits: 8\nScore: 0.6016260385513306\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner1.get_best_hyperparameters()[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:03:28.827960Z","iopub.execute_input":"2024-01-01T10:03:28.828380Z","iopub.status.idle":"2024-01-01T10:03:28.836499Z","shell.execute_reply.started":"2024-01-01T10:03:28.828355Z","shell.execute_reply":"2024-01-01T10:03:28.835381Z"},"trusted":true},"execution_count":108,"outputs":[{"execution_count":108,"output_type":"execute_result","data":{"text/plain":"{'units': 80}"},"metadata":{}}]},{"cell_type":"code","source":"#Getting best model\nmodel = tuner1.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:04:17.015597Z","iopub.execute_input":"2024-01-01T10:04:17.015972Z","iopub.status.idle":"2024-01-01T10:04:17.663463Z","shell.execute_reply.started":"2024-01-01T10:04:17.015948Z","shell.execute_reply":"2024-01-01T10:04:17.662490Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"model.fit(xtrain,ytrain,batch_size=32,epochs=100,initial_epoch=5,validation_split=.02)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:05:16.823330Z","iopub.execute_input":"2024-01-01T10:05:16.823672Z","iopub.status.idle":"2024-01-01T10:05:23.798474Z","shell.execute_reply.started":"2024-01-01T10:05:16.823648Z","shell.execute_reply":"2024-01-01T10:05:23.797239Z"},"trusted":true},"execution_count":110,"outputs":[{"name":"stdout","text":"Epoch 6/100\n19/19 [==============================] - 1s 10ms/step - loss: 0.5144 - accuracy: 0.7621 - val_loss: 0.6676 - val_accuracy: 0.6154\nEpoch 7/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4962 - accuracy: 0.7671 - val_loss: 0.6638 - val_accuracy: 0.6154\nEpoch 8/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4833 - accuracy: 0.7720 - val_loss: 0.6596 - val_accuracy: 0.6154\nEpoch 9/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7770 - val_loss: 0.6587 - val_accuracy: 0.6154\nEpoch 10/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4676 - accuracy: 0.7787 - val_loss: 0.6577 - val_accuracy: 0.6154\nEpoch 11/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7787 - val_loss: 0.6612 - val_accuracy: 0.6154\nEpoch 12/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4591 - accuracy: 0.7804 - val_loss: 0.6617 - val_accuracy: 0.6154\nEpoch 13/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4556 - accuracy: 0.7870 - val_loss: 0.6638 - val_accuracy: 0.6154\nEpoch 14/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4539 - accuracy: 0.7854 - val_loss: 0.6664 - val_accuracy: 0.6154\nEpoch 15/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4512 - accuracy: 0.7837 - val_loss: 0.6731 - val_accuracy: 0.6154\nEpoch 16/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.7787 - val_loss: 0.6722 - val_accuracy: 0.6154\nEpoch 17/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4479 - accuracy: 0.7787 - val_loss: 0.6737 - val_accuracy: 0.6154\nEpoch 18/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7787 - val_loss: 0.6779 - val_accuracy: 0.6154\nEpoch 19/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7854 - val_loss: 0.6831 - val_accuracy: 0.6154\nEpoch 20/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4438 - accuracy: 0.7787 - val_loss: 0.6861 - val_accuracy: 0.6154\nEpoch 21/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4428 - accuracy: 0.7770 - val_loss: 0.6883 - val_accuracy: 0.6154\nEpoch 22/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.7770 - val_loss: 0.6927 - val_accuracy: 0.6154\nEpoch 23/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.7804 - val_loss: 0.6936 - val_accuracy: 0.6154\nEpoch 24/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.7787 - val_loss: 0.6942 - val_accuracy: 0.6154\nEpoch 25/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.7837 - val_loss: 0.7011 - val_accuracy: 0.6154\nEpoch 26/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4376 - accuracy: 0.7770 - val_loss: 0.7043 - val_accuracy: 0.6154\nEpoch 27/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4364 - accuracy: 0.7754 - val_loss: 0.7050 - val_accuracy: 0.6154\nEpoch 28/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4365 - accuracy: 0.7787 - val_loss: 0.7039 - val_accuracy: 0.6154\nEpoch 29/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.7837 - val_loss: 0.7052 - val_accuracy: 0.6154\nEpoch 30/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4340 - accuracy: 0.7837 - val_loss: 0.7032 - val_accuracy: 0.6154\nEpoch 31/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4334 - accuracy: 0.7854 - val_loss: 0.7092 - val_accuracy: 0.6154\nEpoch 32/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4326 - accuracy: 0.7854 - val_loss: 0.7048 - val_accuracy: 0.6154\nEpoch 33/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4315 - accuracy: 0.7804 - val_loss: 0.7090 - val_accuracy: 0.6154\nEpoch 34/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.7870 - val_loss: 0.7108 - val_accuracy: 0.6154\nEpoch 35/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.7887 - val_loss: 0.7026 - val_accuracy: 0.6154\nEpoch 36/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4295 - accuracy: 0.7887 - val_loss: 0.7065 - val_accuracy: 0.6154\nEpoch 37/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.7887 - val_loss: 0.7121 - val_accuracy: 0.6154\nEpoch 38/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.7903 - val_loss: 0.7140 - val_accuracy: 0.6154\nEpoch 39/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4270 - accuracy: 0.7970 - val_loss: 0.7162 - val_accuracy: 0.6154\nEpoch 40/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.7887 - val_loss: 0.7130 - val_accuracy: 0.6154\nEpoch 41/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4263 - accuracy: 0.7903 - val_loss: 0.7165 - val_accuracy: 0.6154\nEpoch 42/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7937 - val_loss: 0.7152 - val_accuracy: 0.6154\nEpoch 43/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4247 - accuracy: 0.8020 - val_loss: 0.7119 - val_accuracy: 0.6154\nEpoch 44/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4244 - accuracy: 0.7953 - val_loss: 0.7116 - val_accuracy: 0.6154\nEpoch 45/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4238 - accuracy: 0.7937 - val_loss: 0.7158 - val_accuracy: 0.6154\nEpoch 46/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.7903 - val_loss: 0.7225 - val_accuracy: 0.6154\nEpoch 47/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4228 - accuracy: 0.7937 - val_loss: 0.7203 - val_accuracy: 0.6154\nEpoch 48/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.7987 - val_loss: 0.7196 - val_accuracy: 0.6154\nEpoch 49/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4213 - accuracy: 0.7953 - val_loss: 0.7231 - val_accuracy: 0.6154\nEpoch 50/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4203 - accuracy: 0.7970 - val_loss: 0.7238 - val_accuracy: 0.6154\nEpoch 51/100\n19/19 [==============================] - 0s 5ms/step - loss: 0.4200 - accuracy: 0.8037 - val_loss: 0.7243 - val_accuracy: 0.6154\nEpoch 52/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4195 - accuracy: 0.7987 - val_loss: 0.7212 - val_accuracy: 0.6154\nEpoch 53/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4186 - accuracy: 0.7937 - val_loss: 0.7305 - val_accuracy: 0.6154\nEpoch 54/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4180 - accuracy: 0.8003 - val_loss: 0.7385 - val_accuracy: 0.6154\nEpoch 55/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4179 - accuracy: 0.8053 - val_loss: 0.7400 - val_accuracy: 0.6154\nEpoch 56/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4171 - accuracy: 0.8037 - val_loss: 0.7373 - val_accuracy: 0.6154\nEpoch 57/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4168 - accuracy: 0.8037 - val_loss: 0.7352 - val_accuracy: 0.6154\nEpoch 58/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4161 - accuracy: 0.8020 - val_loss: 0.7339 - val_accuracy: 0.6154\nEpoch 59/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4155 - accuracy: 0.8003 - val_loss: 0.7360 - val_accuracy: 0.6154\nEpoch 60/100\n19/19 [==============================] - 0s 5ms/step - loss: 0.4150 - accuracy: 0.8037 - val_loss: 0.7429 - val_accuracy: 0.6154\nEpoch 61/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4152 - accuracy: 0.8037 - val_loss: 0.7378 - val_accuracy: 0.6154\nEpoch 62/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8020 - val_loss: 0.7464 - val_accuracy: 0.6154\nEpoch 63/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4137 - accuracy: 0.8020 - val_loss: 0.7459 - val_accuracy: 0.6154\nEpoch 64/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4133 - accuracy: 0.8053 - val_loss: 0.7435 - val_accuracy: 0.6154\nEpoch 65/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4125 - accuracy: 0.8087 - val_loss: 0.7405 - val_accuracy: 0.6154\nEpoch 66/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8020 - val_loss: 0.7352 - val_accuracy: 0.6154\nEpoch 67/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4118 - accuracy: 0.8087 - val_loss: 0.7440 - val_accuracy: 0.6154\nEpoch 68/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4113 - accuracy: 0.8037 - val_loss: 0.7461 - val_accuracy: 0.6154\nEpoch 69/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4103 - accuracy: 0.8103 - val_loss: 0.7399 - val_accuracy: 0.6154\nEpoch 70/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4099 - accuracy: 0.8053 - val_loss: 0.7449 - val_accuracy: 0.6154\nEpoch 71/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4103 - accuracy: 0.8103 - val_loss: 0.7474 - val_accuracy: 0.6154\nEpoch 72/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4095 - accuracy: 0.8087 - val_loss: 0.7413 - val_accuracy: 0.6154\nEpoch 73/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4086 - accuracy: 0.8070 - val_loss: 0.7441 - val_accuracy: 0.6154\nEpoch 74/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4083 - accuracy: 0.8087 - val_loss: 0.7430 - val_accuracy: 0.6154\nEpoch 75/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4077 - accuracy: 0.8087 - val_loss: 0.7481 - val_accuracy: 0.6154\nEpoch 76/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4074 - accuracy: 0.8103 - val_loss: 0.7484 - val_accuracy: 0.6154\nEpoch 77/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4067 - accuracy: 0.8120 - val_loss: 0.7493 - val_accuracy: 0.6154\nEpoch 78/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4064 - accuracy: 0.8136 - val_loss: 0.7592 - val_accuracy: 0.6154\nEpoch 79/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4059 - accuracy: 0.8120 - val_loss: 0.7619 - val_accuracy: 0.5385\nEpoch 80/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.8120 - val_loss: 0.7606 - val_accuracy: 0.6154\nEpoch 81/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4050 - accuracy: 0.8153 - val_loss: 0.7587 - val_accuracy: 0.6154\nEpoch 82/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.4049 - accuracy: 0.8103 - val_loss: 0.7642 - val_accuracy: 0.6154\nEpoch 83/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4039 - accuracy: 0.8136 - val_loss: 0.7540 - val_accuracy: 0.6154\nEpoch 84/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8103 - val_loss: 0.7497 - val_accuracy: 0.6154\nEpoch 85/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4035 - accuracy: 0.8186 - val_loss: 0.7461 - val_accuracy: 0.6154\nEpoch 86/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4028 - accuracy: 0.8153 - val_loss: 0.7505 - val_accuracy: 0.6154\nEpoch 87/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4026 - accuracy: 0.8270 - val_loss: 0.7530 - val_accuracy: 0.5385\nEpoch 88/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4019 - accuracy: 0.8186 - val_loss: 0.7554 - val_accuracy: 0.6154\nEpoch 89/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8203 - val_loss: 0.7558 - val_accuracy: 0.6154\nEpoch 90/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4016 - accuracy: 0.8203 - val_loss: 0.7604 - val_accuracy: 0.6154\nEpoch 91/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4007 - accuracy: 0.8236 - val_loss: 0.7522 - val_accuracy: 0.6154\nEpoch 92/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4005 - accuracy: 0.8203 - val_loss: 0.7611 - val_accuracy: 0.6154\nEpoch 93/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.4002 - accuracy: 0.8203 - val_loss: 0.7584 - val_accuracy: 0.6154\nEpoch 94/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8186 - val_loss: 0.7664 - val_accuracy: 0.5385\nEpoch 95/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.3994 - accuracy: 0.8220 - val_loss: 0.7631 - val_accuracy: 0.6154\nEpoch 96/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.3986 - accuracy: 0.8203 - val_loss: 0.7710 - val_accuracy: 0.5385\nEpoch 97/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8286 - val_loss: 0.7657 - val_accuracy: 0.5385\nEpoch 98/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.3981 - accuracy: 0.8220 - val_loss: 0.7666 - val_accuracy: 0.6154\nEpoch 99/100\n19/19 [==============================] - 0s 4ms/step - loss: 0.3971 - accuracy: 0.8303 - val_loss: 0.7648 - val_accuracy: 0.6154\nEpoch 100/100\n19/19 [==============================] - 0s 3ms/step - loss: 0.3970 - accuracy: 0.8270 - val_loss: 0.7684 - val_accuracy: 0.6154\n","output_type":"stream"},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c29999588e0>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Tune Model For Select Layers","metadata":{}},{"cell_type":"code","source":"def build_model2(hp):\n    model = Sequential()\n    model.add(Dense(80,activation='relu',input_dim=8))\n    for i in range(hp.Int('num_layers',min_value=1,max_value=8)):\n        model.add(Dense(80,activation='relu'))\n    model.add(Dense(1,activation='sigmoid'))\n    model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['accuracy'])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:14:11.154905Z","iopub.execute_input":"2024-01-01T10:14:11.155341Z","iopub.status.idle":"2024-01-01T10:14:11.162970Z","shell.execute_reply.started":"2024-01-01T10:14:11.155309Z","shell.execute_reply":"2024-01-01T10:14:11.161678Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"tuner2 = kt.RandomSearch(build_model2,\n                        objective='val_accuracy',\n                        max_trials=5,\n                        directory='myd',\n                        project_name='layers')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:15:22.458620Z","iopub.execute_input":"2024-01-01T10:15:22.459084Z","iopub.status.idle":"2024-01-01T10:15:22.510927Z","shell.execute_reply.started":"2024-01-01T10:15:22.459008Z","shell.execute_reply":"2024-01-01T10:15:22.509773Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"tuner2.search(xtrain,ytrain,epochs=5,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:16:24.653000Z","iopub.execute_input":"2024-01-01T10:16:24.653426Z","iopub.status.idle":"2024-01-01T10:16:35.630998Z","shell.execute_reply.started":"2024-01-01T10:16:24.653391Z","shell.execute_reply":"2024-01-01T10:16:35.629633Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Trial 5 Complete [00h 00m 02s]\nval_accuracy: 0.7560975551605225\n\nBest val_accuracy So Far: 0.7804877758026123\nTotal elapsed time: 00h 00m 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner2.results_summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:16:53.707811Z","iopub.execute_input":"2024-01-01T10:16:53.708167Z","iopub.status.idle":"2024-01-01T10:16:53.714992Z","shell.execute_reply.started":"2024-01-01T10:16:53.708143Z","shell.execute_reply":"2024-01-01T10:16:53.713493Z"},"trusted":true},"execution_count":116,"outputs":[{"name":"stdout","text":"Results summary\nResults in myd/layers\nShowing 10 best trials\nObjective(name=\"val_accuracy\", direction=\"max\")\n\nTrial 1 summary\nHyperparameters:\nnum_layers: 8\nScore: 0.7804877758026123\n\nTrial 2 summary\nHyperparameters:\nnum_layers: 1\nScore: 0.772357702255249\n\nTrial 3 summary\nHyperparameters:\nnum_layers: 4\nScore: 0.772357702255249\n\nTrial 0 summary\nHyperparameters:\nnum_layers: 7\nScore: 0.7642276287078857\n\nTrial 4 summary\nHyperparameters:\nnum_layers: 5\nScore: 0.7560975551605225\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner2.get_best_hyperparameters(1)[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:17:31.819856Z","iopub.execute_input":"2024-01-01T10:17:31.820286Z","iopub.status.idle":"2024-01-01T10:17:31.828921Z","shell.execute_reply.started":"2024-01-01T10:17:31.820254Z","shell.execute_reply":"2024-01-01T10:17:31.827249Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 8}"},"metadata":{}}]},{"cell_type":"code","source":"#Training Model From Tuner2 Function\nmodel = tuner2.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:18:31.544133Z","iopub.execute_input":"2024-01-01T10:18:31.544519Z","iopub.status.idle":"2024-01-01T10:18:32.380978Z","shell.execute_reply.started":"2024-01-01T10:18:31.544487Z","shell.execute_reply":"2024-01-01T10:18:32.379351Z"},"trusted":true},"execution_count":118,"outputs":[]},{"cell_type":"code","source":"model.fit(xtrain,ytrain,epochs=100,validation_split=0.2,initial_epoch=5)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:19:11.039961Z","iopub.execute_input":"2024-01-01T10:19:11.040411Z","iopub.status.idle":"2024-01-01T10:19:20.391306Z","shell.execute_reply.started":"2024-01-01T10:19:11.040378Z","shell.execute_reply":"2024-01-01T10:19:20.389609Z"},"trusted":true},"execution_count":119,"outputs":[{"name":"stdout","text":"Epoch 6/100\n16/16 [==============================] - 1s 18ms/step - loss: 0.4578 - accuracy: 0.7841 - val_loss: 0.4852 - val_accuracy: 0.7724\nEpoch 7/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8045 - val_loss: 0.4675 - val_accuracy: 0.7724\nEpoch 8/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.7760 - val_loss: 0.4851 - val_accuracy: 0.7805\nEpoch 9/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8106 - val_loss: 0.4607 - val_accuracy: 0.7642\nEpoch 10/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4175 - accuracy: 0.8065 - val_loss: 0.4721 - val_accuracy: 0.7480\nEpoch 11/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.3981 - accuracy: 0.8147 - val_loss: 0.4700 - val_accuracy: 0.7642\nEpoch 12/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3770 - accuracy: 0.8350 - val_loss: 0.5250 - val_accuracy: 0.7398\nEpoch 13/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3789 - accuracy: 0.8411 - val_loss: 0.4831 - val_accuracy: 0.7642\nEpoch 14/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.8574 - val_loss: 0.5714 - val_accuracy: 0.7154\nEpoch 15/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3592 - accuracy: 0.8411 - val_loss: 0.5149 - val_accuracy: 0.7561\nEpoch 16/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3433 - accuracy: 0.8615 - val_loss: 0.5679 - val_accuracy: 0.7480\nEpoch 17/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3158 - accuracy: 0.8554 - val_loss: 0.5321 - val_accuracy: 0.7480\nEpoch 18/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.8737 - val_loss: 0.5188 - val_accuracy: 0.7398\nEpoch 19/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2762 - accuracy: 0.9043 - val_loss: 0.6765 - val_accuracy: 0.7480\nEpoch 20/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.2511 - accuracy: 0.9084 - val_loss: 0.7406 - val_accuracy: 0.7236\nEpoch 21/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2689 - accuracy: 0.8982 - val_loss: 0.6873 - val_accuracy: 0.7073\nEpoch 22/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2508 - accuracy: 0.8921 - val_loss: 0.7095 - val_accuracy: 0.7480\nEpoch 23/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2221 - accuracy: 0.9246 - val_loss: 0.6793 - val_accuracy: 0.6992\nEpoch 24/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2052 - accuracy: 0.9308 - val_loss: 0.9454 - val_accuracy: 0.7073\nEpoch 25/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.2642 - accuracy: 0.9002 - val_loss: 0.7192 - val_accuracy: 0.6911\nEpoch 26/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.1480 - accuracy: 0.9470 - val_loss: 0.8942 - val_accuracy: 0.7236\nEpoch 27/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1750 - accuracy: 0.9348 - val_loss: 0.8463 - val_accuracy: 0.6829\nEpoch 28/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1733 - accuracy: 0.9389 - val_loss: 0.9302 - val_accuracy: 0.6748\nEpoch 29/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9470 - val_loss: 0.9632 - val_accuracy: 0.6829\nEpoch 30/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1335 - accuracy: 0.9511 - val_loss: 0.9360 - val_accuracy: 0.7073\nEpoch 31/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.1576 - accuracy: 0.9430 - val_loss: 1.1621 - val_accuracy: 0.6911\nEpoch 32/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.0926 - accuracy: 0.9715 - val_loss: 1.2254 - val_accuracy: 0.6748\nEpoch 33/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9491 - val_loss: 1.0127 - val_accuracy: 0.7073\nEpoch 34/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0849 - accuracy: 0.9715 - val_loss: 1.1392 - val_accuracy: 0.7154\nEpoch 35/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1369 - accuracy: 0.9430 - val_loss: 1.1763 - val_accuracy: 0.6504\nEpoch 36/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1113 - accuracy: 0.9552 - val_loss: 1.2715 - val_accuracy: 0.6829\nEpoch 37/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9552 - val_loss: 1.4187 - val_accuracy: 0.6748\nEpoch 38/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9817 - val_loss: 1.3449 - val_accuracy: 0.6423\nEpoch 39/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9756 - val_loss: 1.8582 - val_accuracy: 0.7154\nEpoch 40/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9654 - val_loss: 1.5425 - val_accuracy: 0.6911\nEpoch 41/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0596 - accuracy: 0.9756 - val_loss: 1.3802 - val_accuracy: 0.7073\nEpoch 42/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0428 - accuracy: 0.9857 - val_loss: 1.6001 - val_accuracy: 0.6911\nEpoch 43/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0866 - accuracy: 0.9715 - val_loss: 1.6312 - val_accuracy: 0.6748\nEpoch 44/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0967 - accuracy: 0.9695 - val_loss: 1.5191 - val_accuracy: 0.6992\nEpoch 45/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0385 - accuracy: 0.9898 - val_loss: 1.7004 - val_accuracy: 0.6585\nEpoch 46/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0749 - accuracy: 0.9756 - val_loss: 1.5237 - val_accuracy: 0.7073\nEpoch 47/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9857 - val_loss: 1.6604 - val_accuracy: 0.6667\nEpoch 48/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9919 - val_loss: 2.0315 - val_accuracy: 0.6260\nEpoch 49/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9735 - val_loss: 1.5640 - val_accuracy: 0.6911\nEpoch 50/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0220 - accuracy: 0.9939 - val_loss: 1.9958 - val_accuracy: 0.6829\nEpoch 51/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0412 - accuracy: 0.9878 - val_loss: 1.9658 - val_accuracy: 0.6829\nEpoch 52/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0577 - accuracy: 0.9817 - val_loss: 1.8181 - val_accuracy: 0.6911\nEpoch 53/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 0.9980 - val_loss: 2.3755 - val_accuracy: 0.6667\nEpoch 54/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.9756 - val_loss: 1.6593 - val_accuracy: 0.6992\nEpoch 55/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0093 - accuracy: 0.9980 - val_loss: 2.5735 - val_accuracy: 0.6585\nEpoch 56/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0514 - accuracy: 0.9837 - val_loss: 2.1174 - val_accuracy: 0.6504\nEpoch 57/100\n16/16 [==============================] - 0s 4ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 2.5464 - val_accuracy: 0.6911\nEpoch 58/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1507 - accuracy: 0.9674 - val_loss: 2.2372 - val_accuracy: 0.6992\nEpoch 59/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0206 - accuracy: 0.9919 - val_loss: 2.3126 - val_accuracy: 0.6992\nEpoch 60/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0117 - accuracy: 0.9980 - val_loss: 2.4792 - val_accuracy: 0.6992\nEpoch 61/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0838 - accuracy: 0.9776 - val_loss: 2.1247 - val_accuracy: 0.6829\nEpoch 62/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9878 - val_loss: 1.8309 - val_accuracy: 0.6667\nEpoch 63/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.1486 - val_accuracy: 0.6829\nEpoch 64/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6121 - val_accuracy: 0.6829\nEpoch 65/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0297 - accuracy: 0.9939 - val_loss: 2.2651 - val_accuracy: 0.6992\nEpoch 66/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9715 - val_loss: 1.9280 - val_accuracy: 0.6992\nEpoch 67/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0234 - accuracy: 0.9919 - val_loss: 2.2607 - val_accuracy: 0.7073\nEpoch 68/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6209 - val_accuracy: 0.7073\nEpoch 69/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0154 - accuracy: 0.9939 - val_loss: 2.6419 - val_accuracy: 0.6260\nEpoch 70/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0594 - accuracy: 0.9776 - val_loss: 2.2845 - val_accuracy: 0.6829\nEpoch 71/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0071 - accuracy: 0.9980 - val_loss: 2.9918 - val_accuracy: 0.6423\nEpoch 72/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0055 - accuracy: 0.9980 - val_loss: 3.1131 - val_accuracy: 0.6585\nEpoch 73/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0663 - accuracy: 0.9796 - val_loss: 2.3706 - val_accuracy: 0.6829\nEpoch 74/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0996 - accuracy: 0.9715 - val_loss: 1.8664 - val_accuracy: 0.6829\nEpoch 75/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.1659 - val_accuracy: 0.6829\nEpoch 76/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5600 - val_accuracy: 0.6829\nEpoch 77/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0115 - accuracy: 0.9980 - val_loss: 2.6346 - val_accuracy: 0.6748\nEpoch 78/100\n16/16 [==============================] - 0s 6ms/step - loss: 8.9286e-04 - accuracy: 1.0000 - val_loss: 3.0442 - val_accuracy: 0.6748\nEpoch 79/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.0397 - accuracy: 0.9898 - val_loss: 2.8955 - val_accuracy: 0.6829\nEpoch 80/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0414 - accuracy: 0.9837 - val_loss: 2.5434 - val_accuracy: 0.6667\nEpoch 81/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8976 - val_accuracy: 0.6748\nEpoch 82/100\n16/16 [==============================] - 0s 5ms/step - loss: 6.4015e-04 - accuracy: 1.0000 - val_loss: 3.1839 - val_accuracy: 0.6748\nEpoch 83/100\n16/16 [==============================] - 0s 5ms/step - loss: 3.2143e-04 - accuracy: 1.0000 - val_loss: 3.4359 - val_accuracy: 0.6829\nEpoch 84/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.5997e-04 - accuracy: 1.0000 - val_loss: 3.6716 - val_accuracy: 0.6748\nEpoch 85/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.3543e-04 - accuracy: 1.0000 - val_loss: 3.8887 - val_accuracy: 0.6748\nEpoch 86/100\n16/16 [==============================] - 0s 5ms/step - loss: 8.8117e-05 - accuracy: 1.0000 - val_loss: 4.3179 - val_accuracy: 0.6585\nEpoch 87/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.1007 - accuracy: 0.9776 - val_loss: 3.6461 - val_accuracy: 0.6179\nEpoch 88/100\n16/16 [==============================] - 0s 5ms/step - loss: 4.5078e-04 - accuracy: 1.0000 - val_loss: 3.6116 - val_accuracy: 0.6504\nEpoch 89/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.6391e-04 - accuracy: 1.0000 - val_loss: 3.6670 - val_accuracy: 0.6504\nEpoch 90/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.2155e-04 - accuracy: 1.0000 - val_loss: 3.7617 - val_accuracy: 0.6504\nEpoch 91/100\n16/16 [==============================] - 0s 5ms/step - loss: 8.4878e-05 - accuracy: 1.0000 - val_loss: 3.8917 - val_accuracy: 0.6504\nEpoch 92/100\n16/16 [==============================] - 0s 5ms/step - loss: 5.7752e-05 - accuracy: 1.0000 - val_loss: 4.0175 - val_accuracy: 0.6504\nEpoch 93/100\n16/16 [==============================] - 0s 5ms/step - loss: 4.0266e-05 - accuracy: 1.0000 - val_loss: 4.1533 - val_accuracy: 0.6504\nEpoch 94/100\n16/16 [==============================] - 0s 5ms/step - loss: 2.6992e-05 - accuracy: 1.0000 - val_loss: 4.2549 - val_accuracy: 0.6423\nEpoch 95/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.9062e-05 - accuracy: 1.0000 - val_loss: 4.4039 - val_accuracy: 0.6504\nEpoch 96/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.5374e-05 - accuracy: 1.0000 - val_loss: 4.4632 - val_accuracy: 0.6504\nEpoch 97/100\n16/16 [==============================] - 0s 5ms/step - loss: 1.1137e-05 - accuracy: 1.0000 - val_loss: 4.5095 - val_accuracy: 0.6423\nEpoch 98/100\n16/16 [==============================] - 0s 5ms/step - loss: 9.1020e-06 - accuracy: 1.0000 - val_loss: 4.5580 - val_accuracy: 0.6423\nEpoch 99/100\n16/16 [==============================] - 0s 5ms/step - loss: 7.6307e-06 - accuracy: 1.0000 - val_loss: 4.6101 - val_accuracy: 0.6423\nEpoch 100/100\n16/16 [==============================] - 0s 5ms/step - loss: 6.5138e-06 - accuracy: 1.0000 - val_loss: 4.6366 - val_accuracy: 0.6423\n","output_type":"stream"},{"execution_count":119,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c2999a9f3a0>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**You Can See Accuracy Got 1 and Val_accuracy reduce to 64 From 76**","metadata":{}},{"cell_type":"markdown","source":"# Build Tune Function To Get All Perfect Perameter","metadata":{}},{"cell_type":"code","source":"from keras.layers import Dense, Dropout\ndef build_model3(hp):\n    model = Sequential()\n    counter = 0\n    \n    # Loop through the specified number of layers\n    for i in range(hp.Int('num_layers', min_value=1, max_value=10)):\n        if counter == 0:\n            # For the first layer, include input_dim and dropout\n            model.add(\n                Dense(\n                    hp.Int('Units' + str(i), min_value=8, max_value=128, step=8),\n                    activation=hp.Choice('activation' + str(i), values=['relu', 'tanh', 'sigmoid']),\n                    input_dim=8\n                )\n            )\n            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])))\n        else:\n            # For subsequent layers, include dropout\n            model.add(\n                Dense(\n                    hp.Int('Units' + str(i), min_value=8, max_value=128, step=8),\n                    activation=hp.Choice('activation' + str(i), values=['relu', 'tanh', 'sigmoid'])\n                )\n            )\n            model.add(Dropout(hp.Choice('dropout' + str(i), values=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])))\n        counter += 1\n\n    # Output layer\n    model.add(Dense(1, activation='sigmoid'))\n\n    # Compile the model with tunable hyperparameters\n    model.compile(optimizer=hp.Choice('optimizer', values=['rmsprop', 'adam', 'sgd', 'nadam', 'adadelta']),\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:08.393971Z","iopub.execute_input":"2024-01-01T10:50:08.394368Z","iopub.status.idle":"2024-01-01T10:50:08.405997Z","shell.execute_reply.started":"2024-01-01T10:50:08.394337Z","shell.execute_reply":"2024-01-01T10:50:08.404270Z"},"trusted":true},"execution_count":129,"outputs":[]},{"cell_type":"code","source":"tuner3 = kt.RandomSearch(build_model3,\n                        objective='val_accuracy',\n                        max_trials=5,\n                        directory='mtd',\n                        project_name='final')","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:19.373855Z","iopub.execute_input":"2024-01-01T10:50:19.374287Z","iopub.status.idle":"2024-01-01T10:50:19.393402Z","shell.execute_reply.started":"2024-01-01T10:50:19.374254Z","shell.execute_reply":"2024-01-01T10:50:19.392085Z"},"trusted":true},"execution_count":130,"outputs":[{"name":"stdout","text":"Reloading Tuner from mtd/final/tuner0.json\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner3.search(xtrain,ytrain,epochs=5,validation_split=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:23.444327Z","iopub.execute_input":"2024-01-01T10:50:23.444723Z","iopub.status.idle":"2024-01-01T10:50:23.451829Z","shell.execute_reply.started":"2024-01-01T10:50:23.444690Z","shell.execute_reply":"2024-01-01T10:50:23.450736Z"},"trusted":true},"execution_count":131,"outputs":[]},{"cell_type":"code","source":"tuner3.results_summary()","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:27.027634Z","iopub.execute_input":"2024-01-01T10:50:27.029069Z","iopub.status.idle":"2024-01-01T10:50:27.035375Z","shell.execute_reply.started":"2024-01-01T10:50:27.028975Z","shell.execute_reply":"2024-01-01T10:50:27.033904Z"},"trusted":true},"execution_count":132,"outputs":[{"name":"stdout","text":"Results summary\nResults in mtd/final\nShowing 10 best trials\nObjective(name=\"val_accuracy\", direction=\"max\")\n\nTrial 4 summary\nHyperparameters:\nnum_layers: 8\nUnits0: 16\nactivation0: sigmoid\noptimizer: adam\nUnits1: 96\nactivation1: tanh\nUnits2: 40\nactivation2: relu\nUnits3: 16\nactivation3: relu\nUnits4: 80\nactivation4: tanh\nUnits5: 16\nactivation5: tanh\nUnits6: 64\nactivation6: sigmoid\nUnits7: 104\nactivation7: sigmoid\nUnits8: 64\nactivation8: sigmoid\nUnits9: 128\nactivation9: sigmoid\nScore: 0.7804877758026123\n\nTrial 1 summary\nHyperparameters:\nnum_layers: 7\nUnits0: 8\nactivation0: sigmoid\noptimizer: adam\nUnits1: 8\nactivation1: relu\nUnits2: 8\nactivation2: relu\nUnits3: 8\nactivation3: relu\nUnits4: 8\nactivation4: relu\nUnits5: 8\nactivation5: relu\nUnits6: 8\nactivation6: relu\nScore: 0.6341463327407837\n\nTrial 3 summary\nHyperparameters:\nnum_layers: 10\nUnits0: 48\nactivation0: relu\noptimizer: adadelta\nUnits1: 56\nactivation1: sigmoid\nUnits2: 72\nactivation2: sigmoid\nUnits3: 96\nactivation3: sigmoid\nUnits4: 8\nactivation4: sigmoid\nUnits5: 72\nactivation5: sigmoid\nUnits6: 112\nactivation6: relu\nUnits7: 8\nactivation7: relu\nUnits8: 8\nactivation8: relu\nUnits9: 8\nactivation9: relu\nScore: 0.3658536672592163\n\nTrial 0 summary\nHyperparameters:\nnum_layers: 1\nUnits0: 96\nactivation0: tanh\noptimizer: adadelta\nScore: 0.3658536672592163\n\nTrial 2 summary\nHyperparameters:\nnum_layers: 5\nUnits0: 16\nactivation0: tanh\noptimizer: adadelta\nUnits1: 96\nactivation1: relu\nUnits2: 96\nactivation2: relu\nUnits3: 8\nactivation3: relu\nUnits4: 128\nactivation4: sigmoid\nUnits5: 48\nactivation5: sigmoid\nUnits6: 88\nactivation6: sigmoid\nScore: 0.3658536672592163\n","output_type":"stream"}]},{"cell_type":"code","source":"tuner3.get_best_hyperparameters(1)[0].values","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:33.237632Z","iopub.execute_input":"2024-01-01T10:50:33.237980Z","iopub.status.idle":"2024-01-01T10:50:33.244510Z","shell.execute_reply.started":"2024-01-01T10:50:33.237956Z","shell.execute_reply":"2024-01-01T10:50:33.243512Z"},"trusted":true},"execution_count":133,"outputs":[{"execution_count":133,"output_type":"execute_result","data":{"text/plain":"{'num_layers': 8,\n 'Units0': 16,\n 'activation0': 'sigmoid',\n 'optimizer': 'adam',\n 'Units1': 96,\n 'activation1': 'tanh',\n 'Units2': 40,\n 'activation2': 'relu',\n 'Units3': 16,\n 'activation3': 'relu',\n 'Units4': 80,\n 'activation4': 'tanh',\n 'Units5': 16,\n 'activation5': 'tanh',\n 'Units6': 64,\n 'activation6': 'sigmoid',\n 'Units7': 104,\n 'activation7': 'sigmoid',\n 'Units8': 64,\n 'activation8': 'sigmoid',\n 'Units9': 128,\n 'activation9': 'sigmoid'}"},"metadata":{}}]},{"cell_type":"code","source":"final_model = tuner3.get_best_models(num_models=1)[0]","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:36.071756Z","iopub.execute_input":"2024-01-01T10:50:36.072173Z","iopub.status.idle":"2024-01-01T10:50:36.878973Z","shell.execute_reply.started":"2024-01-01T10:50:36.072140Z","shell.execute_reply":"2024-01-01T10:50:36.877759Z"},"trusted":true},"execution_count":134,"outputs":[]},{"cell_type":"code","source":"final_model.fit(xtrain,ytrain,epochs=100,validation_split=0.2,initial_epoch=5)","metadata":{"execution":{"iopub.status.busy":"2024-01-01T10:50:42.503855Z","iopub.execute_input":"2024-01-01T10:50:42.504256Z","iopub.status.idle":"2024-01-01T10:50:52.865091Z","shell.execute_reply.started":"2024-01-01T10:50:42.504224Z","shell.execute_reply":"2024-01-01T10:50:52.863641Z"},"trusted":true},"execution_count":135,"outputs":[{"name":"stdout","text":"Epoch 6/100\n16/16 [==============================] - 2s 18ms/step - loss: 0.5608 - accuracy: 0.7088 - val_loss: 0.5269 - val_accuracy: 0.7724\nEpoch 7/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5675 - accuracy: 0.7067 - val_loss: 0.4967 - val_accuracy: 0.7561\nEpoch 8/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5431 - accuracy: 0.6904 - val_loss: 0.5027 - val_accuracy: 0.7561\nEpoch 9/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5508 - accuracy: 0.7088 - val_loss: 0.5067 - val_accuracy: 0.7886\nEpoch 10/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5294 - accuracy: 0.7373 - val_loss: 0.4851 - val_accuracy: 0.7480\nEpoch 11/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5512 - accuracy: 0.7088 - val_loss: 0.4988 - val_accuracy: 0.7561\nEpoch 12/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7373 - val_loss: 0.4940 - val_accuracy: 0.7480\nEpoch 13/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5349 - accuracy: 0.7047 - val_loss: 0.4945 - val_accuracy: 0.7480\nEpoch 14/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5399 - accuracy: 0.7291 - val_loss: 0.4992 - val_accuracy: 0.7805\nEpoch 15/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5207 - accuracy: 0.7291 - val_loss: 0.4853 - val_accuracy: 0.7480\nEpoch 16/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5398 - accuracy: 0.7352 - val_loss: 0.4903 - val_accuracy: 0.7561\nEpoch 17/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5531 - accuracy: 0.7271 - val_loss: 0.5073 - val_accuracy: 0.7967\nEpoch 18/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5159 - accuracy: 0.7393 - val_loss: 0.4893 - val_accuracy: 0.7480\nEpoch 19/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5271 - accuracy: 0.7312 - val_loss: 0.5129 - val_accuracy: 0.7805\nEpoch 20/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5208 - accuracy: 0.7536 - val_loss: 0.5030 - val_accuracy: 0.7724\nEpoch 21/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5153 - accuracy: 0.7495 - val_loss: 0.4909 - val_accuracy: 0.7398\nEpoch 22/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5137 - accuracy: 0.7556 - val_loss: 0.4975 - val_accuracy: 0.7805\nEpoch 23/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5285 - accuracy: 0.7536 - val_loss: 0.4916 - val_accuracy: 0.7724\nEpoch 24/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5074 - accuracy: 0.7576 - val_loss: 0.4921 - val_accuracy: 0.7805\nEpoch 25/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5188 - accuracy: 0.7515 - val_loss: 0.4840 - val_accuracy: 0.7398\nEpoch 26/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5302 - accuracy: 0.7413 - val_loss: 0.4852 - val_accuracy: 0.7886\nEpoch 27/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4939 - accuracy: 0.7841 - val_loss: 0.4742 - val_accuracy: 0.7886\nEpoch 28/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5091 - accuracy: 0.7719 - val_loss: 0.4660 - val_accuracy: 0.7724\nEpoch 29/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5110 - accuracy: 0.7536 - val_loss: 0.4678 - val_accuracy: 0.7724\nEpoch 30/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7658 - val_loss: 0.4726 - val_accuracy: 0.7805\nEpoch 31/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4983 - accuracy: 0.7556 - val_loss: 0.4800 - val_accuracy: 0.7886\nEpoch 32/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5005 - accuracy: 0.7576 - val_loss: 0.4870 - val_accuracy: 0.7398\nEpoch 33/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5213 - accuracy: 0.7454 - val_loss: 0.4829 - val_accuracy: 0.7724\nEpoch 34/100\n16/16 [==============================] - 0s 7ms/step - loss: 0.4864 - accuracy: 0.7800 - val_loss: 0.4804 - val_accuracy: 0.7805\nEpoch 35/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.7617 - val_loss: 0.4706 - val_accuracy: 0.7805\nEpoch 36/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4969 - accuracy: 0.7699 - val_loss: 0.4772 - val_accuracy: 0.7805\nEpoch 37/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5052 - accuracy: 0.7556 - val_loss: 0.4670 - val_accuracy: 0.7886\nEpoch 38/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4883 - accuracy: 0.7699 - val_loss: 0.4677 - val_accuracy: 0.7886\nEpoch 39/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4845 - accuracy: 0.7576 - val_loss: 0.4589 - val_accuracy: 0.7642\nEpoch 40/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4882 - accuracy: 0.7678 - val_loss: 0.4630 - val_accuracy: 0.7805\nEpoch 41/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4822 - accuracy: 0.7739 - val_loss: 0.4614 - val_accuracy: 0.7724\nEpoch 42/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4972 - accuracy: 0.7658 - val_loss: 0.4626 - val_accuracy: 0.7724\nEpoch 43/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5065 - accuracy: 0.7678 - val_loss: 0.4632 - val_accuracy: 0.7724\nEpoch 44/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4944 - accuracy: 0.7800 - val_loss: 0.4756 - val_accuracy: 0.7886\nEpoch 45/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5063 - accuracy: 0.7739 - val_loss: 0.4664 - val_accuracy: 0.7642\nEpoch 46/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5062 - accuracy: 0.7597 - val_loss: 0.4717 - val_accuracy: 0.7805\nEpoch 47/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4979 - accuracy: 0.7658 - val_loss: 0.4731 - val_accuracy: 0.7805\nEpoch 48/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5013 - accuracy: 0.7576 - val_loss: 0.4772 - val_accuracy: 0.7561\nEpoch 49/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5008 - accuracy: 0.7556 - val_loss: 0.4758 - val_accuracy: 0.7724\nEpoch 50/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4907 - accuracy: 0.7719 - val_loss: 0.4678 - val_accuracy: 0.7642\nEpoch 51/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4953 - accuracy: 0.7637 - val_loss: 0.4694 - val_accuracy: 0.7805\nEpoch 52/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7556 - val_loss: 0.4575 - val_accuracy: 0.7724\nEpoch 53/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4962 - accuracy: 0.7475 - val_loss: 0.4639 - val_accuracy: 0.7724\nEpoch 54/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.7658 - val_loss: 0.4629 - val_accuracy: 0.7724\nEpoch 55/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7760 - val_loss: 0.4795 - val_accuracy: 0.7886\nEpoch 56/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4865 - accuracy: 0.7699 - val_loss: 0.4652 - val_accuracy: 0.7561\nEpoch 57/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4868 - accuracy: 0.7637 - val_loss: 0.4719 - val_accuracy: 0.7967\nEpoch 58/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4922 - accuracy: 0.7658 - val_loss: 0.4766 - val_accuracy: 0.7886\nEpoch 59/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4892 - accuracy: 0.7617 - val_loss: 0.4734 - val_accuracy: 0.7886\nEpoch 60/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4982 - accuracy: 0.7678 - val_loss: 0.4638 - val_accuracy: 0.7724\nEpoch 61/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4848 - accuracy: 0.7637 - val_loss: 0.4587 - val_accuracy: 0.7805\nEpoch 62/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4933 - accuracy: 0.7739 - val_loss: 0.4615 - val_accuracy: 0.7724\nEpoch 63/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4929 - accuracy: 0.7556 - val_loss: 0.4719 - val_accuracy: 0.7561\nEpoch 64/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4808 - accuracy: 0.7780 - val_loss: 0.4744 - val_accuracy: 0.7724\nEpoch 65/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4945 - accuracy: 0.7597 - val_loss: 0.4711 - val_accuracy: 0.7805\nEpoch 66/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.7454 - val_loss: 0.4639 - val_accuracy: 0.7805\nEpoch 67/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7556 - val_loss: 0.4614 - val_accuracy: 0.7724\nEpoch 68/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4842 - accuracy: 0.7719 - val_loss: 0.4674 - val_accuracy: 0.7642\nEpoch 69/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.7597 - val_loss: 0.4709 - val_accuracy: 0.7561\nEpoch 70/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4857 - accuracy: 0.7739 - val_loss: 0.4715 - val_accuracy: 0.7561\nEpoch 71/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4776 - accuracy: 0.7780 - val_loss: 0.4760 - val_accuracy: 0.7561\nEpoch 72/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4873 - accuracy: 0.7678 - val_loss: 0.4762 - val_accuracy: 0.7724\nEpoch 73/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4782 - accuracy: 0.7699 - val_loss: 0.4769 - val_accuracy: 0.7561\nEpoch 74/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4636 - accuracy: 0.7739 - val_loss: 0.4744 - val_accuracy: 0.7642\nEpoch 75/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4874 - accuracy: 0.7576 - val_loss: 0.4868 - val_accuracy: 0.7642\nEpoch 76/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.5030 - accuracy: 0.7536 - val_loss: 0.4719 - val_accuracy: 0.7724\nEpoch 77/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4680 - accuracy: 0.7637 - val_loss: 0.4713 - val_accuracy: 0.7724\nEpoch 78/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4747 - accuracy: 0.7923 - val_loss: 0.4794 - val_accuracy: 0.7561\nEpoch 79/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4777 - accuracy: 0.7739 - val_loss: 0.4720 - val_accuracy: 0.7561\nEpoch 80/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4753 - accuracy: 0.7780 - val_loss: 0.4826 - val_accuracy: 0.7480\nEpoch 81/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4723 - accuracy: 0.7739 - val_loss: 0.4777 - val_accuracy: 0.7561\nEpoch 82/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4806 - accuracy: 0.7678 - val_loss: 0.4872 - val_accuracy: 0.7561\nEpoch 83/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4985 - accuracy: 0.7739 - val_loss: 0.5021 - val_accuracy: 0.7480\nEpoch 84/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4989 - accuracy: 0.7536 - val_loss: 0.4701 - val_accuracy: 0.7642\nEpoch 85/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4694 - accuracy: 0.7536 - val_loss: 0.4809 - val_accuracy: 0.7561\nEpoch 86/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4691 - accuracy: 0.7617 - val_loss: 0.4823 - val_accuracy: 0.7561\nEpoch 87/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4745 - accuracy: 0.7800 - val_loss: 0.4760 - val_accuracy: 0.7642\nEpoch 88/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4674 - accuracy: 0.7963 - val_loss: 0.4792 - val_accuracy: 0.7561\nEpoch 89/100\n16/16 [==============================] - 0s 7ms/step - loss: 0.4749 - accuracy: 0.7658 - val_loss: 0.4645 - val_accuracy: 0.7480\nEpoch 90/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4708 - accuracy: 0.7556 - val_loss: 0.4891 - val_accuracy: 0.7805\nEpoch 91/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4714 - accuracy: 0.7882 - val_loss: 0.4781 - val_accuracy: 0.7642\nEpoch 92/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4798 - accuracy: 0.7576 - val_loss: 0.4956 - val_accuracy: 0.7642\nEpoch 93/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.7943 - val_loss: 0.4960 - val_accuracy: 0.7967\nEpoch 94/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4863 - accuracy: 0.7658 - val_loss: 0.4867 - val_accuracy: 0.7805\nEpoch 95/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4745 - accuracy: 0.7862 - val_loss: 0.4762 - val_accuracy: 0.7724\nEpoch 96/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.7678 - val_loss: 0.4777 - val_accuracy: 0.7724\nEpoch 97/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4823 - accuracy: 0.7821 - val_loss: 0.5022 - val_accuracy: 0.7724\nEpoch 98/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4715 - accuracy: 0.7739 - val_loss: 0.4610 - val_accuracy: 0.7886\nEpoch 99/100\n16/16 [==============================] - 0s 6ms/step - loss: 0.4878 - accuracy: 0.7780 - val_loss: 0.4720 - val_accuracy: 0.7805\nEpoch 100/100\n16/16 [==============================] - 0s 5ms/step - loss: 0.4753 - accuracy: 0.7739 - val_loss: 0.4565 - val_accuracy: 0.7886\n","output_type":"stream"},{"execution_count":135,"output_type":"execute_result","data":{"text/plain":"<keras.src.callbacks.History at 0x7c2a31848b20>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Why Keras Tuner?\nKeras Tuner offers a user-friendly and flexible platform for hyperparameter tuning, enabling data scientists and machine learning practitioners to unlock the full potential of their neural network models. By the end of this notebook, you'll have a solid understanding of how to leverage Keras Tuner to enhance the performance of your neural networks and accelerate your model development workflow.\n\nLet's dive in and discover the art of optimizing neural networks with Keras Tuner!\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}